<!DOCTYPE html> <html lang="kr"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> What Makes Multi-modal Learning Better than Single (Provably) | Wonbeom Jang </title> <meta name="author" content="Wonbeom Jang"> <meta name="description" content="NeurIPS 2021"> <meta name="keywords" content="computer-vision, machine-learning, software-engineer, software-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.wonbeomjang.kr/blog/2023/multimodal-vs-unimodal/"> </head> <body class="fixed-top-nav "> <header> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1352545434285249" crossorigin="anonymous"></script> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Wonbeom </span> Jang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">What Makes Multi-modal Learning Better than Single (Provably)</h1> <p class="post-meta"> November 19, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/tag/multi-modal"> <i class="fa-solid fa-hashtag fa-sm"></i> multi-modal</a>   <a href="/blog/tag/paper"> <i class="fa-solid fa-hashtag fa-sm"></i> paper</a>     ·   <a href="/blog/category/multi-modal"> <i class="fa-solid fa-tag fa-sm"></i> multi-modal</a>   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> paper</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>우리 세상에는 다양한 modality가 존재합니다. 직관적으로 여러 modal의 정보를 결합(fusion)하면, uni-modal보다 더 나은 성능을 얻을 수 있을 것이라 생각됩니다. 이에 대해 다음과 같은 질문을 던질 수 있습니다.</p> <p align="center"> _multi-modal learning이 uni-modal learning보다 항상 좋은 성능을 제공할까?_ </p> <p>저자는 이 질문을 중심으로 연구를 시작하며, 다음 두 가지를 중점적으로 살펴보았습니다.</p> <ol> <li><strong>어떤 상황에서 multi-modal이 uni-modal보다 성능이 좋은가?</strong></li> <li><strong>multi-modal 학습이 더 나은 성능을 제공하는 이유는 무엇인가?</strong></li> </ol> <p>이를 통해 저자는 다음과 같은 기여를 했습니다:</p> <ul> <li>Multi-modal learning을 population risk 관점에서 설명하고, latent representation quality와 연결 지었습니다.</li> <li>특정 modality subset으로 학습한 network의 성능 상한선을 이론적으로 제시했습니다.</li> <li>Modalities의 subset만 사용할 경우 성능이 저하되는 이유를 분석했습니다.</li> </ul> <p>결론은 다음과 같습니다:</p> <ul> <li>Multiple modalities는 특정 modal subset보다 낮은 population risk를 갖습니다.</li> <li>이는 multi-modal 학습이 더 정확한 latent space representation을 제공하기 때문입니다.</li> </ul> <p>이제 세부적으로 살펴보겠습니다.</p> <hr> <h1 id="the-multi-modal-learning-formulation">The Multi-modal Learning Formulation</h1> <p align="center"> <img src="/assets/post/image/multi-modal-vs-uni-modal/figure1.png" width="80%"> </p> <h2 id="multi-modal-데이터의-수학적-정의">Multi-modal 데이터의 수학적 정의</h2> <p>K개의 modalities에 대해 데이터는 다음과 같이 표현됩니다.<br> \(\mathbb{x}:=(x^{(1)},\cdots,x^{(K)})\)<br> 이때, \(x^{(k)} \in \mathcal{X}^{(k)}\) 이며, 전체 input data space는 다음과 같습니다.<br> \(\mathcal{X}=\mathcal{X}^{1} \times \cdots \times \mathcal{X}^{k}\)</p> <p>target domain은 \(\mathcal{Y}\), 공통된 latent space는 \(\mathcal{Z}\)로 정의합니다. True mapping은 다음과 같습니다:<br> \(g^\star: \mathcal{X} \mapsto \mathcal{Z}, \quad h^\star: \mathcal{Z} \mapsto \mathcal{Y}\)</p> <p>데이터의 분포는 다음과 같이 정의됩니다.<br> \(\mathbb{P}_\mathcal{D}(\mathbb{x},y)\triangleq\mathbb{P}_{y|x}(y|h^\star\circ g^\star(\mathbb{x}))\mathbb{P}_\mathbb{x}(\mathbb{x})\)</p> <h2 id="subset-modalities">Subset Modalities</h2> <p>우리는 K개의 modalities 중 \(\mathcal{N} \leq \mathcal{M}\) 인 subset을 선택할 수 있습니다.<br> 이때 modality의 superset은 다음과 같습니다:<br> \(\mathcal{X}^\prime := (\mathcal{X}^{(1)}\cup\bot)\times\cdots\times(\mathcal{X}^{(K)}\cup\bot)\)<br> 여기서 \(\bot\)은 특정 modality를 사용하지 않음을 의미합니다.</p> <p>modality 선택 함수 \(p_\mathcal{M}\)는 다음과 같이 정의됩니다.</p> \[p_\mathcal{M}(\mathbb{x})^{(k)}= \begin{cases} \mathbb{x}^{(k)} &amp; \text{if } k\in\mathcal{M}, \\ \bot &amp; \text{else}. \end{cases}\] <h2 id="학습-목표-empirical-risk-minimization-erm">학습 목표: Empirical Risk Minimization (ERM)</h2> <p>우리의 목표는 ERM에 따라 학습 objective를 최소화하는 것입니다:</p> \[\text{min } \hat{r}(h\circ g_\mathcal{M}) = \frac{1}{m}\sum_{i=1}^ml(h\circ g_\mathcal{M}(\mathbb{x}_i),y_i), \quad \text{s.t. } h \in \mathcal{H}, g_\mathcal{M} \in \mathcal{G}.\] <p>최종적으로 population risk는 다음과 같이 정의됩니다.<br> \(r(h\circ g_\mathcal{M})=\mathbb{E}_{(\mathbb{x}_i, y_i)\sim\mathcal{D}}[\hat{r}(h\circ g_\mathcal{M})]\)</p> <hr> <h1 id="main-result">Main Result</h1> <h3 id="latent-representation-quality-정의">Latent Representation Quality 정의</h3> <blockquote> <p><strong>Definition 1.</strong><br> 데이터 분포에서 학습된 latent representation mapping \(g \in \mathcal{G}\)의 <em>quality</em>는 다음과 같이 정의됩니다.<br> \(\eta(g) = \text{inf}_{h\in\mathcal{H}}[r(h\circ g)-r(h^\star\circ g^\star)]\)<br> 즉, true latent space와의 차이를 측정하며, 이를 latent space quality라 부릅니다.</p> </blockquote> <hr> <h2 id="rademacher-complexity">Rademacher Complexity</h2> <p>Model complexity를 측정하는 Rademacher complexity는 다음과 같습니다.</p> <ul> <li>\(\mathcal{F}\)를 \(\mathbb{R}^d \mapsto \mathbb{R}\)인 함수 집합으로 정의합니다.</li> <li>\(Z_1, \ldots, Z_m\)은 \(\mathbb{R}^d\)에서 iid로 샘플된 데이터이고, \(S=(Z_1,\ldots,Z_m)\)라고 합니다.</li> </ul> <p>Empirical Rademacher complexity는 다음과 같이 정의됩니다.<br> \(\hat{\mathfrak{R}}_S(\mathcal{F}):=\mathbb{E}_\sigma[\underset{f\in\mathcal{F}}{\text{sup}} \frac{1}{m}\sum_{i=1}^m\sigma_if(Z_i)]\)</p> <p>여기서 \(\sigma=(\sigma_1,...,\sigma_m)^\top\)이고, \(\sigma_i\)는 \(\{-1, 1\}\)에서 uniform하게 추출된 random variable입니다.</p> <hr> <h2 id="latent-space-quality와-population-risk의-관계">Latent Space Quality와 Population Risk의 관계</h2> <blockquote> <p><strong>Theorem 1.</strong><br> \(S = \{(x_i, y_i)\}_{i=1}^m\)이 데이터셋이고, \(\mathcal{M}, \mathcal{N}\)은 modality의 두 subset입니다. \(\mathcal{M}\)과 \(\mathcal{N}\)으로 각각 학습된 empirical risk minimizers \((\hat{h}_\mathcal{M}, \hat{g}_\mathcal{M})\)와 \((\hat{h}_\mathcal{N}, \hat{g}_\mathcal{N})\)에 대해, 다음이 성립합니다.</p> </blockquote> <p>\(r(\hat{h}_{\mathcal{M}} \circ \hat{g}_{\mathcal{M}}) - r(\hat{h}_{\mathcal{N}} \circ \hat{g}_{\mathcal{N}}) \leq \gamma_{\mathcal{S}}(\mathcal{M},\mathcal{N}) + \text{O}(1/m)\)<br> 여기서 \(\gamma_S(\mathcal{M},\mathcal{N})\triangleq\eta(\hat{g}_\mathcal{M})-\eta(\hat{g}_\mathcal{N})\)는 latent space quality의 차이입니다.</p> <hr> <h1 id="experiment">Experiment</h1> <h2 id="dataset-iemocap">Dataset: IEMOCAP</h2> <p>Interactive Emotional Dyadic Motion Capture 데이터셋을 사용했습니다. 데이터셋에는 Text, Video, Audio 정보가 포함되어 있으며, 발화자의 감정을 예측하는 것이 목표입니다.</p> <h3 id="결과">결과</h3> <ol> <li><strong>Modalities가 많을수록 정확도가 향상됩니다.</strong></li> <li><strong>Sample이 적을 경우, subset modalities가 더 나은 성능을 보일 수 있습니다.</strong></li> <li><strong>Multi-modal 학습은 더 나은 latent space quality를 제공합니다.</strong></li> </ol> <p align="center"> <img src="/assets/post/image/multi-modal-vs-uni-modal/table3.png" width="80%"> </p> <hr> <h2 id="결론">결론</h2> <ul> <li>데이터 크기가 충분히 클 때 multi-modal을 사용하는 것이 유리합니다.</li> <li>multi-modal 학습은 더 정확한 latent space representation을 학습할 수 있습니다.</li> <li>이론적 분석과 실험 결과 모두 이를 뒷받침합니다.</li> </ul> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/unsupervised-image-restoration/">Invariant Representation for Unsupervised Image Restoration</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2024/pretraining-data-dection-for-large-language-models/">Pretraining Data Detection for Large Language Models: A Divergence-based Calibration Method 설명</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/SENet/">학부생이 본 SENet</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/heapq-vs-priority-q/">[Python] 우선순위 큐 (heapq vs priority queue)</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/proper-use-classification-features-in-object-detection/">Proper Reuse of Image Classification Features Improves Object Detection</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"wonbeomjang/wonbeomjang.github.io","data-repo-id":"R_kgDOIsrE7Q","data-category":"Comments","data-category-id":"DIC_kwDOIsrE7c4CaZnD","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"ko",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wonbeom Jang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: December 30, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-NH0GKRG1BP"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-NH0GKRG1BP");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>