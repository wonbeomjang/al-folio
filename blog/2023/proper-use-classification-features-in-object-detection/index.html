<!DOCTYPE html> <html lang="kr"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1352545434285249" crossorigin="anonymous"></script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Proper Reuse of Image Classification Features Improves Object Detection | Wonbeom Jang</title> <meta name="author" content="Wonbeom Jang"> <meta name="description" content="Neck is important"> <meta name="keywords" content="computer-vision, machine-learning, software-engineer, software-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.wonbeomjang.kr/blog/2023/proper-use-classification-features-in-object-detection/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Wonbeom </span>Jang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Proper Reuse of Image Classification Features Improves Object Detection</h1> <p class="post-meta">April 8, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/transfer-learning"> <i class="fas fa-tag fa-sm"></i> transfer-learning</a>   <a href="/blog/category/object-detection"> <i class="fas fa-tag fa-sm"></i> object-detection</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>기존 object detection을 학습시킬 때 imagenet backbone을 사용하여 pretrain후 transfer learning을 통해 target dataset에 대해 학습을 했다. 이 상황에서 보통 object detection의 backbone만 pretrain시키고 detection관련 module은 random으로 initalize시킨다. 따라서 이에 관한 연구가 있었는데 크게 두 가지가 있다.</p> <ul> <li>Pretrain으로 사용한 classiciation data의 량 만큼 object detection에 긍정적 영향을 끼친다.</li> <li>In-domain dataset으로 학습시간을 길게 가져가면 pretrained model과 scratch model의 성능차이가 없어진다.</li> </ul> <p>저자들은 두 연구를 분석하기위해 backbone network를 classification dataset에 대해 학습 후 paramter를 freeze시켜 object detection model을 학습시켰다.</p> <h1 id="methodology">Methodology</h1> <p>기존에 사용하는 일반적인 학습방법은 다음과 같다.</p> <ol> <li>ImageNet, JFT-300M과 같은 classification dataset에서 backbone network를 학습시킨다.</li> <li>Backbone network에 detection specific component를 추가한다. ex) RPN, FPN, NAS-FPN</li> <li>Target dataset에 대하여 재학습시킨다.</li> </ol> <p>하지만 저자는 다음과 같은 방법을 제안한다.</p> <ol> <li>ImageNet, JFT-300M과 같은 classification dataset에서 backbone network를 학습시킨다.</li> <li>Backbone network를 freeze시킨 후 detection specific component를 추가한다.</li> <li>Target dataset에 대하여 재학습시킨다.</li> </ol> <p>결론적으로 backbone을 freeze시키는 것만 달라졌다.</p> <h1 id="experiment">Experiment</h1> <p>실험결과를 요약하자면 다음과 같다.</p> <h2 id="detectoin-specific-capacity">Detectoin-Specific capacity</h2> <ul> <li>FPN, RPN, Detection Cascade 등은 network의 generalzation에 도움을 준다.</li> <li>해당 요소들의 capacity가 충분하면 backbone freezing이 fine-tuning과 training scratch보다 좋은 성능을 보인다.</li> <li>Backbone pretraining시 classification dataset의 수가 많아질수록 성능이 높아진다.</li> <li> </li> </ul> <p><strong>Data Augmentation</strong></p> <p>Instance segmentation 실험에서는 Data augmentation은 다음을 사용했다.</p> <ul> <li>Large Scale Jittering</li> <li>Copy-and-paste augmentation</li> </ul> <p><strong>Architecture</strong></p> <p>첫번째 실험의 model architecture는 다음과 같다.</p> <ul> <li>Faster-RCNN</li> <li>ResNet50</li> <li>FPN or NAS-FPN</li> <li>Cascade head</li> </ul> <p>두 번째 실험의 model architecutre는 다음과 같다.</p> <ul> <li>Mask-RCNN</li> <li>EfficientNet-B7</li> <li>NAS-FPN</li> <li>Cascade head</li> </ul> <p><strong>Hyper parameter</strong></p> <p>해당실험은 자원이 한정되어있는 상황을 가정했기 때문에 batch size는 64, learning rate는 그에 맞게 0.08로 설정했다.</p> <p><strong>Dataset</strong></p> <p>Detection dataset으로 MS-COCO, LVIS를 사용했고, classification dataset으로는 ImageNet, JFT-300M을 사용했다.</p> <h2 id="resnet50--faster-rcnn">ResNet50 + Faster-RCNN</h2> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled.png" width="50%"> </p> <p>모든 실험서 공통적으로 classification pretrain시 이미지수가 비교적으로 적은 ImageNet보다 JFT-300M의 성능이 좋았다. 또한 FPN을 사용했을 때보다 parameter수가 더 많은 NAS-FPN, Cascade head를 사용했을 때 성능이 좋았다. 이는 backbone network가 다른 domain에서 학습이 되어 이를 generalize하는데 충분한 capacity가 필요하다고 한다.</p> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%201.png" width="50%"> </p> <p>pretraing과 fine-tuning의 관계를 알아보기위해 실험을 진행했다. 첫 번째를 보았을 때 traning schedule이 짧을 경우엔 pretranig에 사용된 classfication dataset의 크기가 커질수록 성능이 좋았따. 두 번째를 보았을 때 training schedule이 길수록 pretran classification dataset에따른 성능차이가 줄어든 것을 보아 pretran은 성능에 도움이 되지 않는다고 한다. 저자는 이를 확장하여 large dataset으로 pretrain하고 backbone을 freeze시켜 long traning schedule으로부터 knowledge를 보호한다. 또한 high-capacity detector component사용하여 domain이 다른 문제를 해결했다.</p> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%202.png" width="50%"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%203.png" width="80%"> </p> <p>Backbone은 ImageNet에서 학습시켰다. 따라서 object detection과 domain gap이 발생하는데 이는 detector component가 해결할 수 있다. FPN을 사용할 경우 generalize하는데 capacity가 부족해 성능감소가 발생했다. 하지만 NAS-FPN과 Cascade head를 추가했을 때 성능에 이득이 있었다.</p> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%204.png" width="50%"> </p> <p>결론적으로 충분한 capacity의 detector component를 사용하고 backbone network를 freeze 시키면 trainable parameter가 줄어들고 FLOPS도 줄어들어 학습속도와 memory가 줄어든다.</p> <h2 id="efficientnet-b7mask-rcnn">EfficientNet-B7+Mask-RCNN</h2> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%205.png" width="50%"> </p> <p>capacity가 충분한 detector component를 추가하고 backbone을 freeze시키는 것이 좋은 성능을 냈으며 Copy-Paste라는 강한 augmentation을 사용했을 떄도 성능향상이 있었다.</p> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%206.png" width="100%"> </p> <p>small object, midium object 모두 성능에서 향상이 있었다.</p> <h2 id="furthurmore">Furthurmore</h2> <p align="center"> <img src="/assets/post/image/proper-reuse-of-image-classification-features-improve-object-detection/Untitled%207.png" width="50%"> </p> <p>Backbone Freeze가 만병통치약은 아니었다. Freeze시킨 경에서도 residual adapter를 사용하면 더 좋은 성능을 냈다.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">읽어볼 거리</h2> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/tinyvit/">TinyViT</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/meta-pseudo-label/">Meta Pseudo Labels</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/dine/">DINE: Domain Adaptation from Single and Multiple Black-box Predictors</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/rethinking-batch-in-batchnorm/">Rethinking “Batch” in BatchNorm</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/integral-neural-network/">Integral Neural Network</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusAttributes={src:"https://giscus.app/client.js","data-repo":"wonbeomjang/wonbeomjang.github.io","data-repo-id":"R_kgDOIsrE7Q","data-category":"Comments","data-category-id":"DIC_kwDOIsrE7c4CaZnD","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":"light","data-lang":"ko",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Wonbeom Jang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: November 25, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>