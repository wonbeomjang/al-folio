<!DOCTYPE html> <html lang="kr"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <script async src="https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js?client=ca-pub-1352545434285249" crossorigin="anonymous"></script> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>Convolutional Character Network | Wonbeom Jang</title> <meta name="author" content="Wonbeom Jang"> <meta name="description" content="CharNet; single stage scene text detection"> <meta name="keywords" content="computer-vision, machine-learning, software-engineer, software-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?19f3075a2d19613090fe9e16b564e1fe" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.wonbeomjang.kr/blog/2023/convolutional-character-network/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"><span class="font-weight-bold">Wonbeom </span>Jang</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog<span class="sr-only">(current)</span></a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects</a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">Convolutional Character Network</h1> <p class="post-meta">March 7, 2023</p> <p class="post-tags"> <a href="/blog/2023"> <i class="fas fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/scene-text-detection"> <i class="fas fa-tag fa-sm"></i> scene-text-detection</a>   <a href="/blog/category/scene-text-recognition"> <i class="fas fa-tag fa-sm"></i> scene-text-recognition</a>   <a href="/blog/category/paper"> <i class="fas fa-tag fa-sm"></i> paper</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="intorduction">Intorduction</h1> <p>대부분 Scene Text Detection은 Text Detection과 Text Recognization으로 나누어져 있다. 하지만 이러한 방법은 representation을 제대로 학습하지 못해 성능이 하락한다. 따라서 저자는 Detection과 Recognization이 합쳐진 CharNet을 제안한다. 또한 CNN과 RNN을 같이 학습하는 것이 어려운 과제이기 때문에 Character 단위로 Text를 예측하는 모델을 제시한다.</p> <h1 id="convolutional-character-network">Convolutional Character Network</h1> <p align="center"> <img src="/assets/post/image/legacy/convolutional_neural_network_architecture.png" width="80%"> </p> <p>모델은 Detection Branch와 Character Branch로 나뉘어져 있다. Character branch는 character detection과 recognization을 위해 만들어졌고 Text detection은 Text의 bbox를 예측한다.</p> <h2 id="backbone">Backbone</h2> <p>Backbone으로 ResNet50을사용하였고 높은 해상돌르 위하하여 featuremap size를 1/4로만 줄인다. 또한 두 개의 Hour Glass Module을 쌓는다. 이때 Hourglass-104에서 down sampling과 마지막 몇 개의 layer를 제거하여 Hourglass-88을 제작한다.</p> <h2 id="character-branch">Character Branch</h2> <p>Word 단위로 인식하는 네트워크들은 필연적으로 RNN계열의 모델이 들어간다. 하지만 이로인해 더 많은 데이터와 작업이 필요하므로 word단위가 아닌 character단위로 만드는 것이 성능을 높힐 수 있다. 따라서 저자는 Character branch를 도입했다.</p> <p>Character branch는 Text instance segmentation, character detection, character recognization으로 이루어져있으며 앞 2가지는 3개(3x3, 3x3, 1x1)의 CNN layer을 가지고 있으며 character recognization은 4개의 CNN layer를 가지고 있다.</p> <ul> <li>Text instance segmentation: text와 non-text를 구분하는 역할로 2개의 channel을 가지고 있다</li> <li>Character detection: character의 bbox와 orientation을 예측하는 5개의 channel을 가지고 있다.</li> <li>Character recognization: 26개의 알파펫, 10개의 숫자, 32개의 특수문자를 분류한다.</li> </ul> <p>이 때 Character의 bbox는 95%이상의 confidence를 갖는 것만 이용한다.</p> <h2 id="text-detection-branch">Text Detection Branch</h2> <p>Text detection branch는 더 높은 수준의 representation을 학습한다. 또한 word 사이 간격이 가까우면 character로 word를 만들기 어렵기 때문에 text detection을 같이사용한다.</p> <ul> <li>Multi-Orientation Text: text, non-text를 나누는 2체널 bbox와 orientation을 학습하는 5체널을 학습한다.</li> <li>Curved Text: Direction layer를 사용한다.</li> <li>Generation of Final Results: 만약 Text bbox와 character bbox이 겹치는 정도가 일정 수준을 넘어가면 해당 text에 character가 있다고 판단한다.</li> </ul> <h1 id="iterative-character-detection">Iterative Character Detection</h1> <p>저자는 text detection/recognization을 위해 character-level annotation이 필요하나 많은 데이터셋은 word-level annotation을 가지고 있다. 이 때 Synth800k는 두 수준의 annotation을 모두 가지고 있는데 이는 현실데이터와 달라 현실데이터로 fine-tuning하지 않으면 성능이 낮다. 따라서 저자는 다음과 같은 전략을 취한다.</p> <ol> <li>Synth800k을 사용하여 pretrained weight를 제작한다.</li> <li>1번에서 학습시킨 모델과 word-level annotation을 이용하여 weakly-suprevised learning을 한다. 이 때 character bbox와 달리 character class는 label로 사용하지 않는다.</li> <li>2번 과정에서 만들어진 모델을 가지고 weakly-suprevised learning을 반복하여 성능을 높힌다.</li> </ol> <p>Weakly supervised learning은 1번을 학습시킨 모델을 사용하여 word-level annotation에서 character level annotation(label)을 만드는 것인데 만약 예측이 다음과 같은 조건을 만족시키면 “correct”라고 가정한다.</p> <p><em>Text instance에 존재하는 character bounding box의 개수와 text instance의 label(word)가 일치하면 해당 pseudo label은 correct하다고 결정한다.</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">읽어볼 거리</h2> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/cross-domain-adaptive-teacher-for-object-detection/">Cross-Domain Adaptive Teacher for Object Detection</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2022/fitnet/">FitNet</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/integral-neural-network/">Integral Neural Network</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/tinyvit/">TinyViT</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/edgevit/">EdgeViT</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusAttributes={src:"https://giscus.app/client.js","data-repo":"wonbeomjang/wonbeomjang.github.io","data-repo-id":"R_kgDOIsrE7Q","data-category":"Comments","data-category-id":"DIC_kwDOIsrE7c4CaZnD","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":"light","data-lang":"ko",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,a])=>giscusScript.setAttribute(t,a)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2023 Wonbeom Jang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: November 21, 2023. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.8/dist/medium-zoom.min.js" integrity="sha256-7PhEpEWEW0XXQ0k6kQrPKwuoIomz8R8IYyuU1Qew4P8=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?7b30caa5023af4af8408a472dc4e1ebb"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?d633890033921b33e0ceb13d22340a9c"></script> <script defer src="/assets/js/common.js?acdb9690d7641b2f8d40529018c71a01"></script> <script defer src="/assets/js/copy_code.js?c9d9dd48933de3831b3ee5ec9c209cac" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>