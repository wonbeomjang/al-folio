<!DOCTYPE html> <html lang="kr"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer | Wonbeom Jang </title> <meta name="author" content="Wonbeom Jang"> <meta name="description" content="transformer for mobile device"> <meta name="keywords" content="computer-vision, machine-learning, software-engineer, software-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.wonbeomjang.kr/blog/2023/mobile-vit/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Wonbeom </span> Jang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">MobileViT: Light-weight, General-purpose, and Mobile-friendly Vision Transformer</h1> <p class="post-meta"> March 29, 2023 </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/transformer"> <i class="fa-solid fa-tag fa-sm"></i> transformer</a>   <a href="/blog/category/mobile-backbone"> <i class="fa-solid fa-tag fa-sm"></i> mobile-backbone</a>   <a href="/blog/category/backbone"> <i class="fa-solid fa-tag fa-sm"></i> backbone</a>   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> paper</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <h1 id="introduction">Introduction</h1> <p>Transformer는 NLP에서 좋은 성능을 보였고 vision task에서도 ViT를 통하여 좋은 성능을 보여줬다. 이는 global representation을 학습할 수 있기 때문인데 이와같은 성질은 light weight제작시 단점이 된다. 기존의 CNN에서 light weight 제작은 인접픽셀끼리 높은 상관관계를 가지고 있다라는 inductive bias의 덕을 보았기 때문이다. 따라서 저자는 CNN과 ViT의 장점을 합쳐놓은 MobileViT를 제안하였고, light weight, general-purpose, low latency를 달성하였다.</p> <h1 id="mobilevit">MobileViT</h1> <h2 id="vit">ViT</h2> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-vit.png" width="80%"> </p> <ol> <li>Input \(X \in \mathbb{R}^{H \times W \times C}\)를 flatten patch \(X_f \in \mathbb{R}^{N \times PC}\)로 만든다.</li> <li>Fixed <em>d</em>-dimensional space \(X_p \in \mathbb{R}^{N \times d}\)에 projection 시킨다.</li> <li> <em>L</em>개의 transformer block을 이용하여 inner-patch representation을 학습한다.</li> </ol> <p>ViT의 computational cost는 \(O(N^2d)\)이고, \(P=wh\)이다.</p> <p>ViT는 spatial inductive bias를 무시하기 때문에 더 많은 파라미터를 요구한다.</p> <h2 id="mobilevit-architecture">MobileVit Architecture</h2> <p align="center"> <img src="/assets/post/image/legacy/mobilevit.png" width="80%"> </p> <p>MobileViT block은 위와 같다. MobileViT는 local global featyure를 적은 파라미터를 학습하기 위해 구상되었다.</p> <ol> <li>(Local feature) Input tensor \(X \in \mathbb{R}^{H \times W \times C}\)을 standard \(n \times n\) convolution layer와 point wise convolution을 이용하여 \(X_L \in \mathbb{R}^{X \times W \times d}\) 를 만든다.</li> <li>\(X_L\)을 non-overlapping patch인 \(X_U \in \mathbb{R}^{P \times N \times d}\)로 unfold한다. 이 때 \(P=wh, N=\frac{HW}{P}\)이고, \(h \leq n, w \leq n\)이다.</li> <li>(Global feature) 패치 \(p \in \{1, ... ,P\}\)에 대하여 inter-patch relationship을 학습하기 위해 transformer를 사용한 후 \(X_G \in \mathbb{R}^{P \times N \times d}\)를 얻는다.</li> </ol> \[X_G(p)=Transformer(X_U(p)), 1 \leq p \leq P\] <ol> <li>이후 point-wise convolution으로 차원을 \(C\)로 만들고 \(X\)와 concatenation연산을 한다.</li> <li>또 다른 \(n \times n\) convolution을 통하여 concatenation한 결과를 fusion한다.</li> </ol> <p>위의 과정을 통해 local information을 \(X_U(p)\)에 encode하고, global information을 \(X_G(p)\)에 encode한다.</p> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-cnn-patch-relationship.png" width="80%"> </p> <p>위의 그림에서 볼 수 있 듯 convolution을 통해 local feature를 encode 한 후 transformer연산을 통해 inter-patch relationship을 encode하여 결과적으로 한 pixel이 다른 모든 pixel을 고려할 수 있게되었다.</p> <h3 id="relationship-to-convolution">Relationship to convolution</h3> <p>Standard convolution은 다음 3가지 연산의 스택으로 볼 수 있다.</p> <ol> <li>Unfolding</li> <li>Matrix multiplication</li> <li>Folding</li> </ol> <p>이 때 MobileViT block은 matrix multiplication(local processing )에서 transformer(global processing)로 변경되었으므로 <em>transformer as convolution</em>으로 볼 수 있다.</p> <h3 id="light-weight">Light-weight.</h3> <p>다른 ViT계열 모델들은 transformer만 사용하여 inter-patch relationship을 계산하여 image-specific inductive bias의 정보를 잃게되었다. 하지만 MobileViT block은 convolution-like한 특성을 가지고 있어 다른 모델보다 경량화가 가능한 것이다.</p> <h3 id="computational-cost">Computational cost</h3> <p>MobileViT \(O(N^2Pd)\), ViT는 \(O(N^2d)\)이다. MobileViT는 ViT보다 비효율적이지만 실제로는 DeIT보다 2배 더 적은 FLOPs와 1.8%의 성능향상이 되었다.</p> <h3 id="mobilevit-architecture-1">MobileViT architecture</h3> <p>light-weight CNN을 고려하여 S, XS, XXS 모델을 만들었고, 처음 layer는 3x3 standard convolution layer를 사용하고 다음은 MobileNetv2(MV2) block과 MobileViT block을 사용한다. MobileViT block에서는 3x3 CNN을 사용하였고 \(h=w=2\)를 사용하였다. MV2는 down-sampling의 역할을 수행한다.</p> <h2 id="multi-scale-sampler-for-training-efficiency">MULTI-SCALE SAMPLER FOR TRAINING EFFICIENCY</h2> <p>일반적인 ViT모델들은 여러 스케일의 모델들을 만든 후 fine-tuning할수밖에 없다. 하지만 MobileViT는 multi-scale traning이 가능하고 이 때 GPU성능을 끌어올리기 위해 batch-size를 resoution마다 유동적이게 관리했다. Resolution set \(S={(H_1, W_1),...,(H_n, W_n)}\)에 대하여 최대 resolution이 \((H_t, W_t) \in S\)일 때, t번째 resolution \((H_t, W_t) \in S\)의 batch size는 \(b_t=\frac{H_nW_nb}{H_tW_t}\)이다.</p> <h1 id="experimental-results">EXPERIMENTAL RESULTS</h1> <h2 id="image-classification-on-the-imagenet-1k-dataset">IMAGE CLASSIFICATION ON THE IMAGENET-1K DATASET</h2> <ul> <li>Nvidia GPU 8개</li> <li>epoch: 300</li> <li>batch size: 1024</li> <li>AdamW optimizer</li> <li>label smoothing cross-entropy (0.1)</li> <li>multi-scale sampler (\(S=\{(160,160),(192,192),(256,256),(288,288),(320,320)\}\))</li> <li>learning rate scheduler: warmup+cosine (0.0002 → 0.002 for 3k, anneal to 0.0002)</li> <li>L2 weight decay 0.01</li> <li>Random resized cropping and horizontal flipping</li> </ul> <h3 id="comparison-with-cnns">Comparison with CNNs</h3> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-comperision-with-cnn.png" width="80%"> </p> <h3 id="comparison-with-vits">Comparison with ViTs.</h3> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-compersition-with-vit.png" width="80%"> </p> <p>ViT계열 모델들은 augmentation에 민감하다 따라서 basic과 advanced로 나누엇다.</p> <h2 id="mobile-object-detection">MOBILE OBJECT DETECTION</h2> <p>MS-COCO에서 평가하였고 SSD에서 backbone만을 교체하여 실험하였다.</p> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-comparsition-with-detection.png" width="50%"> </p> <h2 id="mobile-semantic-segmentation">MOBILE SEMANTIC SEGMENTATION</h2> <p>DeepLabv3를 사용하였으며 데이터셋은 pascal voc 2012를 사용했다.</p> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-comparsition-segmentation.png" width="50%"> </p> <h2 id="performance-on-mobile-devices">PERFORMANCE ON MOBILE DEVICES</h2> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-comparisoin-using-iphone.png" width="80%"> </p> <p>CorML을 사용하여 iPhone12에서 실험을 진행했을 때 patch size별로 실험을 했을 때 모든 모델들은 real-time에서 동작하였다.</p> <p align="center"> <img src="/assets/post/image/legacy/mobilevit-performance-using-iphone.png" width="50%"> </p> <p>하지만 mobilenet과 같은 CNN모델보다는 성능이 안좋았다.</p> <p>저자는 이를 하드웨어 optimization이 지원되지 않아서라고 추측한다.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/edgevit/">EdgeViT</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/tinyvit/">TinyViT</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/fastattention/">FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/mobileone/">MobileOne: An Improved One millisecond Mobile Backbone</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/simple-baselines-for-image-retoration/">Simple Baselines for Image Restoration</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"wonbeomjang/wonbeomjang.github.io","data-repo-id":"R_kgDOIsrE7Q","data-category":"Comments","data-category-id":"DIC_kwDOIsrE7c4CaZnD","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"ko",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wonbeom Jang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: October 01, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>