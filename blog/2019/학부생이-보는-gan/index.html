<!DOCTYPE html> <html lang="kr"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> 학부생이 보는 GAN | Wonbeom Jang </title> <meta name="author" content="Wonbeom Jang"> <meta name="description" content="개발을 좋아하는 딥러닝 리서쳐 장원범입니다. "> <meta name="keywords" content="computer-vision, machine-learning, software-engineer, software-engineering"> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.css"> <link rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%E2%9A%9B%EF%B8%8F&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://www.wonbeomjang.kr/blog/2019/%ED%95%99%EB%B6%80%EC%83%9D%EC%9D%B4-%EB%B3%B4%EB%8A%94-gan/"> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> <span class="font-weight-bold">Wonbeom </span> Jang </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About </a> </li> <li class="nav-item "> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">Projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV </a> </li> <li class="nav-item "> <a class="nav-link" href="/repositories/">Repositories </a> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">학부생이 보는 GAN</h1> <p class="post-meta"> September 15, 2019 </p> <p class="post-tags"> <a href="/blog/2019"> <i class="fa-solid fa-calendar fa-sm"></i> 2019 </a>   ·   <a href="/blog/category/gan"> <i class="fa-solid fa-tag fa-sm"></i> gan</a>   <a href="/blog/category/paper"> <i class="fa-solid fa-tag fa-sm"></i> paper</a>   </p> </header> <article class="post-content"> <div id="markdown-content"> <p>논문 링크: <a href="https://arxiv.org/pdf/1406.2661.pdf" rel="external nofollow noopener" target="_blank">Ganerative Adversarial Network</a><br><br> GAN은 2014년도에 나온 논문으로 현재 많은 연구에 영향을 끼치고 있고 Yann LeCun이 혁명적인 아이디어라고 극찬한했다. GAN은 Image Generation에 관한 기초 모델로 이를 활용해 늙은 사진, 언경쓴 사진 등 원하는 이미지를 만들어낼 수 있다.</p> <h2 id="contribution">Contribution</h2> <p>이 논문에 Contribution은 다음과 같다.</p> <ol> <li>이후 연구가 활발히 진행되는 GAN의 기본적인 이론적인 개념을 제시했다.</li> <li>ganerate된 이미지는 하나의 지점으로 수렴하며 이 지점은 하나뿐인 global optimum이라는 것을 증명했다.</li> </ol> <h2 id="basic-concept">Basic Concept</h2> <p>“Adversarial”이라는 단어는 적대적인 이라는 뜻을 갖습니다. 논문 제목에서 알 수 있듯 이 논문에서 두 네트워크는 서로 적대적인 관계에 있으며 서로 경쟁하면서 학습해 나간다.</p> <p align="center"><img src="https://t4.daumcdn.net/thumb/R720x0/?fname=http://t1.daumcdn.net/brunch/service/user/1oU7/image/CxJSZ32137590w5Aeo4Yeg-m8dg.png" width="80%"></p> <p>다음 두 네트워크 Generator, Discriminator가 있다. Generator는 이미지를 만들어내는 네트워크이고 Discriminator는 이미지들이 Generator에서 만들어진 이미지인지 실제 데이터셋에 있는 실제 이미지인지 구분한다. GAN 논문에서는 이것을 지폐위조범과 경찰로 묘사했다.</p> <p>지폐위조범인 Generator 들킬 위험이 없는 위조지폐를 만드는 것이 목표다. 그리고 경찰인 Discriminator는 이 위조지폐를 찾아내는 것을 목표로 하고있습니다. 이러한 상황에서 각각의 네트워크들은 자신들의 성능들을 높일것이고 결과적으로 위조지폐가 완벽해서 실제지폐와 구분 할 수 없다. (p=0.5)</p> <p>수학적으로 접근해보면 다음과 같다. Generator는 우리가 갖고있는 data들의 distribution을 모사한다. real data를 \(x\), Generator가 입력으로 z를 받아 뽑은 Sample data를 \(G(z))\)라 하겠다. (z는 보통 Gaussian noise이다,) 만약 Discriminator가 잘 학습이 되 었다면 \(D(x)=1, D(G(z))=0\)이 될 것이고, Generator가 학습니 잘 된다면 D(G(z))=1이 될 것이다. Discriminator는 minimum으로 Generator는 maximun으로 각각 경쟁하며 학습해서 해서 min-max problem이다.</p> <h3 id="loss-function">Loss Function</h3> <p>위를 수식으로 정의하면 다음과 같다.</p> <center> $$min_G max_D V(D,G) = E_{x~p_{data}}[logD(x)] + E_{x~p_z(z)}[log(1-D(G(z)))]$$ </center> <p>이해가 잘 안된다면 극단적으로 접근하면 됩니다. Discriminator가 학습이 잘 되었다면 \(D(x)=1, D(G(z))=0\)가 될 것이고, 결과적으로 \(V(D,G)=0\)으로 maximum이 될 것이다. 반대로 Generator가 학습니 잘 되었다면 \(D(G(z))=1\)이 될 것이고 \(V(D,G)=-\infty\)로 minimun이 될 것이다.</p> <p align="center"><img src="https://1.bp.blogspot.com/-_ZpVHCkqwJI/WHjwzlgki8I/AAAAAAAABKk/e3xQukjtHBoxoQyLA7Fn-GhL7t8mgBFMwCK4B/s640/%25EA%25B7%25B8%25EB%25A6%25BC5.PNG" width="80%"></p> <p>GAN 논문에서 제시하고 있는 Distribution인데요. 검은색 점선은 real data distribution, 초록색 점선은 Generator distribution, 보라색 접선은 Discriminator distribution입니다. 초기상태 (a)에서는 비교적 Discriminator가 real data와 sample data를 잘 판별했으나 학습이 될 수록 real data와 sample data의 distribution이 비슷해져 Discriminator가 각각의 입력을 받았을 때, 출력하는 예측값은 0.5가 됩니다.</p> <h3 id="global-optimality-p_gp_data">Global Optimality \(p_g=p_{data}\)</h3> <p><strong>Proposition 1.</strong> generator G가 고정되었을때 최적의 dicriminator D는</p> <center> $$D^*_G(x)=\frac {p_{data}(x)}{p_{data} + p_g(x)}$$ </center> <p><strong>Proof.</strong></p> <center> $$min_G max_D V(D,G) = E_{x~p_{data}}[logD(x)] + E_{x~p_z(z)}[log(1-D(G(z)))]$$ $$V(G,D)=\int_x p_{data}(x)log(D(x))dx + \int_zp_z(z)log(1-D(G(z)))dz$$ $$V(G,D)=\int_x p_{data}(x)log(D(x)) + p_z(z)log(1-D(G(z)))dz$$ </center> <p>어떤 \((a, b) \in R^2\setminus\{0,0\}\)에서, 함수 \(y \rightarrow alog(y) + blog(y)\)는 [0, 1]범위에서 최댓값 \(\frac{a}{a+b}\)을 갖는다.</p> <p>위의 식을 다음과 같이 변형할 수 있다.</p> <center> $$C(G)= max_D(G,D)$$ $$ = E_{x~p_{data}}[logD^*_G(x)] + E_{x~p_z(z)}[log(1-D^*_G(G(z)))]$$ $$ = E_{x~p_{data}}[logD^*_G(x)] + E_{x~p_z(z)}[log(1-D^*_G(x))]$$ $$ = E_{x~p_{data}}[log\frac {p_{data}(x)}{p_{data} + p_g(x)}] + E_{x~p_z(z)}[log\frac {p_{g}(x)}{p_{data} + p_g(x)}]$$ </center> <p><strong>Theorem 1.</strong> \(C(G)\)의 global minimum은 오직 \(p_g=p_{data}\)뿐이고, 이때 \(C(G)=-log4\)이다.</p> <p>직관적으로 생각했을 때 \(p_g=p_{data}\)이면 \(D^*_G(G)=\frac {1}{2}\)이다.</p> <center> $$C(G)=E_{x~p_{data}}[-log2] + E_{x~p_z(z)}[-log2] = -log4$$ </center> <p>이를 다음과 같이 생각할 수 있다.</p> <center> $$E_{x~data}[log\frac {p_{data}(x)}{p_{data} + p_g(x)}] + E_{x~p_g}[log\frac {p_{g}(x)}{p_{data} + p_g(x)}]$$ $$C(G)=-log(4) + KL(p_{data}||\frac{p_{data} + p_g}{2}) + KL(p_{g}||\frac{p_{data} + p_g}{2})$$ $$C(G)=-log(4) + 2*JSD(p_{data}||p_{g})$$ </center> <p>Jensen-Shannon divergence의 범위는 \([0, \infty]\)이이고 그 최소점은 \(p_{g}=p_{data}\)이다. 따라서 C(G)의 최소값은 \(-log(4)\)이다.</p> <h3 id="convergence-of-algorithm">Convergence of Algorithm</h3> <p><strong>Proposition 2.</strong> 만약 G과 D가 gradient decent알고리즘으로 충분히 학습된다면 D는 다음 식에서 주어진 G과 \(p_g\)에대해 optimum에 도달하게 된다.</p> <center> $$ = E_{x~p_{data}}[logD^*_G(x)] + E_{x~p_z(z)}[log(1-D^*_G(G(z)))]$$ </center> <p><strong>Proof</strong></p> <p>if \(f(p_g)=sup_{D\in}f_D(p_g)\) and \(f_D(p_g)\) is convex in \(p_g\) every \(D\), then \(\vartheta f_{D^*}(p_g) \in \vartheta f\) if \(D^*=argsup_{D\in D}f_D(p_g)\)</p> <p>여기서 \(f_D(p_g)\)는 앞에서 살펴본 \(C(G)\)와 같습니다. \(C(G)\)는 JS divergence으로 convex함수입니다. 이때 모든 D에서 이 식은 성립하므로 D의 optimal인 f_{D^*}(p_g)도 convex함수이다. 따라서 우리가 풀고자하는 문제가 convex함수이기 때문에 gradient decent알고지음을 사용하면 global optimum에 도달한다.</p> <h3 id="limitation">Limitation</h3> <p>앞서 살펴본 내용들을 생각한다면 혁신적인 아이디어는 맞다. 하지만 모든 초기연구가 그렇듯 한계가 있다.</p> <h4 id="unstable">Unstable</h4> <p>사실 Loss함수 입장에서보면 minimum이든 maximum이든 어느쪽으로가든 상관이 없다. 즉</p> <center> $$min_G max_D V(D,G) = E_{x~p_{data}}[logD(x)] + E_{x~p_z(z)}[log(1-D(G(z)))]$$ </center> <p>여기서 Generator를 잘 학습시키는 것 대신 Discriminator를 잘 속이는 것으로 학습방향이 흘러갈수있다. 예를들어 mnist dataset에서 Generator는 Discriminator를 잘 속이기 위해 숫자 6만 만들어낸다고 하자. 그러면 Discriminator는 숫자 6이 나오면 Generator에서 나오는 것으로 판단하고 6이라는 이미지는 fake image라고 판단한다. 이후 Generator는 Discriminator의 판단을 속이기 위해 8을 만들어낼 것이고, 앞선 상황이 반복될 것이다.</p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/unsupervised-image-restoration/">Invariant Representation for Unsupervised Image Restoration</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/byol/">Bootstrap your own latent</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/%EB%84%A4%ED%8A%B8%EC%9B%8C%ED%81%AC-%EA%B2%BD%EB%9F%89%ED%99%94-EffientNet/">[네트워크 경량화] EfficientNet</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2021/NASNet/">[AutoML] NASNet</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/multimodal-vs-unimodal/">What Makes Multi-modal Learning Better than Single (Provably)</a> </li> <div id="giscus_thread" style="max-width: 800px; margin: 0 auto;"> <script>let giscusTheme=localStorage.getItem("theme"),giscusAttributes={src:"https://giscus.app/client.js","data-repo":"wonbeomjang/wonbeomjang.github.io","data-repo-id":"R_kgDOIsrE7Q","data-category":"Comments","data-category-id":"DIC_kwDOIsrE7c4CaZnD","data-mapping":"title","data-strict":"1","data-reactions-enabled":"1","data-emit-metadata":"0","data-input-position":"bottom","data-theme":giscusTheme,"data-lang":"ko",crossorigin:"anonymous",async:""},giscusScript=document.createElement("script");Object.entries(giscusAttributes).forEach(([t,e])=>giscusScript.setAttribute(t,e)),document.getElementById("giscus_thread").appendChild(giscusScript);</script> <noscript>Please enable JavaScript to view the <a href="http://giscus.app/?ref_noscript" rel="external nofollow noopener" target="_blank">comments powered by giscus.</a> </noscript> </div> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Wonbeom Jang. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. Photos from <a href="https://unsplash.com" target="_blank" rel="external nofollow noopener">Unsplash</a>. Last updated: January 25, 2024. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://unpkg.com/bootstrap-table@1.22.1/dist/bootstrap-table.min.js"></script> <script src="/assets/js/no_defer.js?2930004b8d7fcd0a8e00fdcfc8fc9f24"></script> <script defer src="/assets/js/common.js?4a129fbf39254905f505c7246e641eaf"></script> <script defer src="/assets/js/copy_code.js?7254ae07fe9cc5f3a10843e1c0817c9c" type="text/javascript"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> </body> </html>